{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Imports e Leitura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Leitura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cleaned_data_for_modelling.csv')\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Feature Engineering\n",
    "\n",
    "Nessa etapa, que eu considero a mais crucial da modelagem, eu crio as features que nos permitirão modelar o problema em questão, que é a previsão do DAU.\n",
    "\n",
    "Tendo em mente que a única feature que nós teremos no momento da previsão será **category**, e que as restantes precisarão ser atrasadas, pois não teremos nenhuma delas no momento da previsão (daily ratings, daily reviews, etc), eu pensei em modelar o problema como uma série temporal, de forma que para prever quantos usuários teremos no dia seguinte, usamos os dados de 7 dias para trás (1 semana). Sendo assim, o principal input para o modelo será o próprio DAU do aplicativo para dias anteriores ao que queremos prever, visto que teremos esses dados no momento da previsão.\n",
    "\n",
    "Também fiz duas features relacionadas a datas que podem trazer picos de utilização, como feriados nacionais e finais de semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[\"appId\", \"date\"])\n",
    "\n",
    "def lagged_features(df, lags=7):\n",
    "\n",
    "    lagged_data = []\n",
    "\n",
    "    for app in df[\"appId\"].unique():\n",
    "        app_data = df[df[\"appId\"] == app].copy()\n",
    "        for lag in range(1, lags + 1):\n",
    "            app_data[f\"dauReal_t-{lag}\"] = app_data[\"dauReal\"].shift(lag)\n",
    "        app_data[\"dauReal_t\"] = app_data[\"dauReal\"]\n",
    "        lagged_data.append(app_data)\n",
    "    \n",
    "    return pd.concat(lagged_data)\n",
    "\n",
    "df_lagged = lagged_features(df, lags=7)\n",
    "\n",
    "# Dropo as linhas com valores nulos, visto que faltam datas na nossa janela temporal\n",
    "df_lagged = df_lagged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55820/1790318904.py:6: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df_lagged[\"is_brazilian_holiday\"] = df_lagged[\"date\"].isin(brazil_holidays)\n"
     ]
    }
   ],
   "source": [
    "# Checa se a data é um final de semana\n",
    "df_lagged[\"is_weekend\"] = df_lagged[\"date\"].dt.weekday.isin([5, 6])\n",
    "\n",
    "# Checa se a data é um feriado brasileiro\n",
    "brazil_holidays = holidays.Brazil(years=2024)\n",
    "df_lagged[\"is_brazilian_holiday\"] = df_lagged[\"date\"].isin(brazil_holidays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Encoding\n",
    "\n",
    "Nesta seção eu faço o encoding da coluna **category** para formato numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/label_encoder.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df_lagged['category'] = label_encoder.fit_transform(df_lagged['category'])\n",
    "\n",
    "joblib.dump(label_encoder, \"../models/label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged = df_lagged[\n",
    "    [\n",
    "        'appId','date','dauReal_t-1', 'dauReal_t-2', 'dauReal_t-3', \n",
    "        'dauReal_t-4', 'dauReal_t-5', 'dauReal_t-6', \n",
    "        'dauReal_t-7', 'category', 'is_weekend', \n",
    "        'is_brazilian_holiday', 'dauReal_t'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appId</th>\n",
       "      <th>date</th>\n",
       "      <th>dauReal_t-1</th>\n",
       "      <th>dauReal_t-2</th>\n",
       "      <th>dauReal_t-3</th>\n",
       "      <th>dauReal_t-4</th>\n",
       "      <th>dauReal_t-5</th>\n",
       "      <th>dauReal_t-6</th>\n",
       "      <th>dauReal_t-7</th>\n",
       "      <th>category</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_brazilian_holiday</th>\n",
       "      <th>dauReal_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>com.app.10626</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>275086.0</td>\n",
       "      <td>287584.0</td>\n",
       "      <td>247458.0</td>\n",
       "      <td>259606.0</td>\n",
       "      <td>264645.0</td>\n",
       "      <td>206984.0</td>\n",
       "      <td>223700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>236586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>com.app.10626</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>236586.0</td>\n",
       "      <td>275086.0</td>\n",
       "      <td>287584.0</td>\n",
       "      <td>247458.0</td>\n",
       "      <td>259606.0</td>\n",
       "      <td>264645.0</td>\n",
       "      <td>206984.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>195633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>com.app.10626</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>195633.0</td>\n",
       "      <td>236586.0</td>\n",
       "      <td>275086.0</td>\n",
       "      <td>287584.0</td>\n",
       "      <td>247458.0</td>\n",
       "      <td>259606.0</td>\n",
       "      <td>264645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>298509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>com.app.10626</td>\n",
       "      <td>2024-04-02</td>\n",
       "      <td>298509.0</td>\n",
       "      <td>195633.0</td>\n",
       "      <td>236586.0</td>\n",
       "      <td>275086.0</td>\n",
       "      <td>287584.0</td>\n",
       "      <td>247458.0</td>\n",
       "      <td>259606.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>293935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>com.app.10626</td>\n",
       "      <td>2024-04-03</td>\n",
       "      <td>293935.0</td>\n",
       "      <td>298509.0</td>\n",
       "      <td>195633.0</td>\n",
       "      <td>236586.0</td>\n",
       "      <td>275086.0</td>\n",
       "      <td>287584.0</td>\n",
       "      <td>247458.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>281329.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            appId       date  dauReal_t-1  dauReal_t-2  dauReal_t-3  \\\n",
       "7   com.app.10626 2024-03-30     275086.0     287584.0     247458.0   \n",
       "8   com.app.10626 2024-03-31     236586.0     275086.0     287584.0   \n",
       "9   com.app.10626 2024-04-01     195633.0     236586.0     275086.0   \n",
       "10  com.app.10626 2024-04-02     298509.0     195633.0     236586.0   \n",
       "11  com.app.10626 2024-04-03     293935.0     298509.0     195633.0   \n",
       "\n",
       "    dauReal_t-4  dauReal_t-5  dauReal_t-6  dauReal_t-7  category  is_weekend  \\\n",
       "7      259606.0     264645.0     206984.0     223700.0         1        True   \n",
       "8      247458.0     259606.0     264645.0     206984.0         1        True   \n",
       "9      287584.0     247458.0     259606.0     264645.0         1       False   \n",
       "10     275086.0     287584.0     247458.0     259606.0         1       False   \n",
       "11     236586.0     275086.0     287584.0     247458.0         1       False   \n",
       "\n",
       "    is_brazilian_holiday  dauReal_t  \n",
       "7                  False   236586.0  \n",
       "8                  False   195633.0  \n",
       "9                  False   298509.0  \n",
       "10                 False   293935.0  \n",
       "11                 False   281329.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolhi treinar os modelos utilizando a Time-Series Cross Validation, uma forma de entendermos como eles estão performando utilizando as janelas temporais para tentar prever o futuro próximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_lagged[['dauReal_t-1', 'dauReal_t-2', 'dauReal_t-3', 'dauReal_t-4', 'dauReal_t-5', 'dauReal_t-6','dauReal_t-7', 'category', 'is_weekend', 'is_brazilian_holiday']]\n",
    "y = df_lagged['dauReal_t']\n",
    "\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Modelos\n",
    "\n",
    "Numa primeira iteração, utilizei uma combinação de três modelos que considero essenciais para um comparativo.\n",
    "\n",
    "**Regressão Linear**:\n",
    "- Simples, ideal para estabelecer um baseline.\n",
    "\n",
    "**Random Forest**:\n",
    "- Um modelo que utiliza a técnica de bagging (prevalece a previsão com mais votações dos modelos fracos) e geralmente fornece resultados muito robustos.\n",
    "\n",
    "**XGBoost**\n",
    "- Modelo que utiliza a técnica de boosting (modelos fracos são treinados sequencialmente para gerar um mais forte) e também fornece resultados robustos, além de ser extremamente eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando Linear Regression...\n",
      "  Fold 1/5... | MAE: 41612.010915892184 | R2: 0.9902596839390214\n",
      "  Fold 2/5... | MAE: 118134.61580416061 | R2: 0.9786088719105785\n",
      "  Fold 3/5... | MAE: 39290.659382855214 | R2: 0.9427719156521275\n",
      "  Fold 4/5... | MAE: 59791.88642221178 | R2: 0.9690514243541916\n",
      "  Fold 5/5... | MAE: 36400.74035353994 | R2: 0.9943490624349015\n",
      "  Metrics for Linear Regression:\n",
      "    Mean MAE: 59045.98, Std MAE: 30656.31\n",
      "    Mean R²: 0.98, Std R²: 0.02\n",
      "\n",
      "Treinando XGBoost...\n",
      "  Fold 1/5... | MAE: 59399.74171798851 | R2: 0.9755801729092635\n",
      "  Fold 2/5... | MAE: 236630.30348198322 | R2: 0.9223029088370256\n",
      "  Fold 3/5... | MAE: 22390.264546226463 | R2: 0.9436339053857424\n",
      "  Fold 4/5... | MAE: 50622.24515755251 | R2: 0.9616022285270205\n",
      "  Fold 5/5... | MAE: 43760.8937005321 | R2: 0.9785421155577025\n",
      "  Metrics for XGBoost:\n",
      "    Mean MAE: 82560.69, Std MAE: 77999.80\n",
      "    Mean R²: 0.96, Std R²: 0.02\n",
      "\n",
      "Treinando Random Forest...\n",
      "  Fold 1/5... | MAE: 49425.9983196456 | R2: 0.97538341268552\n",
      "  Fold 2/5... | MAE: 200503.66388830292 | R2: 0.9343440607788257\n",
      "  Fold 3/5... | MAE: 20727.56940339664 | R2: 0.9481371087123113\n",
      "  Fold 4/5... | MAE: 42053.6471496468 | R2: 0.9675056748689495\n",
      "  Fold 5/5... | MAE: 39146.99952483565 | R2: 0.9828950838951664\n",
      "  Metrics for Random Forest:\n",
      "    Mean MAE: 70371.58, Std MAE: 65748.74\n",
      "    Mean R²: 0.96, Std R²: 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_reports = {}\n",
    "\n",
    "# Dicionário com os modelos que serão testados\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Treinando {model_name}...\")\n",
    "    \n",
    "    mae_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        \n",
    "        # Divido os dados em treino e teste para esse Fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Treina o modelo\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Faz a previsão e calcula as métricas\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae_score = mean_absolute_error(y_test, y_pred)\n",
    "        mae_scores.append(mae_score)\n",
    "        \n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        print(f\"  Fold {fold + 1}/{n_splits}... | MAE: {mae_score} | R2: {r2}\")\n",
    "    \n",
    "    model_reports[model_name] = {\n",
    "        \"Mean MAE\": np.mean(mae_scores),\n",
    "        \"Std MAE\": np.std(mae_scores),\n",
    "        \"Mean R²\": np.mean(r2_scores),\n",
    "        \"Std R²\": np.std(r2_scores),\n",
    "    }\n",
    "\n",
    "    print(f\"  Metrics for {model_name}:\")\n",
    "    print(f\"    Mean MAE: {np.mean(mae_scores):.2f}, Std MAE: {np.std(mae_scores):.2f}\")\n",
    "    print(f\"    Mean R²: {np.mean(r2_scores):.2f}, Std R²: {np.std(r2_scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Hyperparameter Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.705051979426657, gamma=7, learning_rate=0.2387586688716479, max_depth=5, n_estimators=218, reg_alpha=0.4141186324855385, reg_lambda=0.350931334899144, subsample=0.8697521170952103; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.705051979426657, gamma=7, learning_rate=0.2387586688716479, max_depth=5, n_estimators=218, reg_alpha=0.4141186324855385, reg_lambda=0.350931334899144, subsample=0.8697521170952103; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.705051979426657, gamma=7, learning_rate=0.2387586688716479, max_depth=5, n_estimators=218, reg_alpha=0.4141186324855385, reg_lambda=0.350931334899144, subsample=0.8697521170952103; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.705051979426657, gamma=7, learning_rate=0.2387586688716479, max_depth=5, n_estimators=218, reg_alpha=0.4141186324855385, reg_lambda=0.350931334899144, subsample=0.8697521170952103; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.705051979426657, gamma=7, learning_rate=0.2387586688716479, max_depth=5, n_estimators=218, reg_alpha=0.4141186324855385, reg_lambda=0.350931334899144, subsample=0.8697521170952103; total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.9186941777766422, gamma=9, learning_rate=0.02806554771929606, max_depth=10, n_estimators=266, reg_alpha=0.06231294084407148, reg_lambda=0.13830853827857517, subsample=0.676793698814209; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9186941777766422, gamma=9, learning_rate=0.02806554771929606, max_depth=10, n_estimators=266, reg_alpha=0.06231294084407148, reg_lambda=0.13830853827857517, subsample=0.676793698814209; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9186941777766422, gamma=9, learning_rate=0.02806554771929606, max_depth=10, n_estimators=266, reg_alpha=0.06231294084407148, reg_lambda=0.13830853827857517, subsample=0.676793698814209; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9186941777766422, gamma=9, learning_rate=0.02806554771929606, max_depth=10, n_estimators=266, reg_alpha=0.06231294084407148, reg_lambda=0.13830853827857517, subsample=0.676793698814209; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.9186941777766422, gamma=9, learning_rate=0.02806554771929606, max_depth=10, n_estimators=266, reg_alpha=0.06231294084407148, reg_lambda=0.13830853827857517, subsample=0.676793698814209; total time=   5.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.7224162561505759, gamma=9, learning_rate=0.014285310742471472, max_depth=5, n_estimators=97, reg_alpha=0.45366534380629897, reg_lambda=0.15544805405054332, subsample=0.8757762656702482; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.7224162561505759, gamma=9, learning_rate=0.014285310742471472, max_depth=5, n_estimators=97, reg_alpha=0.45366534380629897, reg_lambda=0.15544805405054332, subsample=0.8757762656702482; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.7224162561505759, gamma=9, learning_rate=0.014285310742471472, max_depth=5, n_estimators=97, reg_alpha=0.45366534380629897, reg_lambda=0.15544805405054332, subsample=0.8757762656702482; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.7224162561505759, gamma=9, learning_rate=0.014285310742471472, max_depth=5, n_estimators=97, reg_alpha=0.45366534380629897, reg_lambda=0.15544805405054332, subsample=0.8757762656702482; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.7224162561505759, gamma=9, learning_rate=0.014285310742471472, max_depth=5, n_estimators=97, reg_alpha=0.45366534380629897, reg_lambda=0.15544805405054332, subsample=0.8757762656702482; total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.9061979941786817, gamma=2, learning_rate=0.07645185888630145, max_depth=8, n_estimators=181, reg_alpha=0.09545503921499346, reg_lambda=0.7558005328358816, subsample=0.9363151766549711; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9061979941786817, gamma=2, learning_rate=0.07645185888630145, max_depth=8, n_estimators=181, reg_alpha=0.09545503921499346, reg_lambda=0.7558005328358816, subsample=0.9363151766549711; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9061979941786817, gamma=2, learning_rate=0.07645185888630145, max_depth=8, n_estimators=181, reg_alpha=0.09545503921499346, reg_lambda=0.7558005328358816, subsample=0.9363151766549711; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9061979941786817, gamma=2, learning_rate=0.07645185888630145, max_depth=8, n_estimators=181, reg_alpha=0.09545503921499346, reg_lambda=0.7558005328358816, subsample=0.9363151766549711; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9061979941786817, gamma=2, learning_rate=0.07645185888630145, max_depth=8, n_estimators=181, reg_alpha=0.09545503921499346, reg_lambda=0.7558005328358816, subsample=0.9363151766549711; total time=   2.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.8997767208035865, gamma=4, learning_rate=0.05996280567850356, max_depth=8, n_estimators=276, reg_alpha=0.717031151159837, reg_lambda=0.42417807246068207, subsample=0.8251420508738814; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8997767208035865, gamma=4, learning_rate=0.05996280567850356, max_depth=8, n_estimators=276, reg_alpha=0.717031151159837, reg_lambda=0.42417807246068207, subsample=0.8251420508738814; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8997767208035865, gamma=4, learning_rate=0.05996280567850356, max_depth=8, n_estimators=276, reg_alpha=0.717031151159837, reg_lambda=0.42417807246068207, subsample=0.8251420508738814; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8997767208035865, gamma=4, learning_rate=0.05996280567850356, max_depth=8, n_estimators=276, reg_alpha=0.717031151159837, reg_lambda=0.42417807246068207, subsample=0.8251420508738814; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8997767208035865, gamma=4, learning_rate=0.05996280567850356, max_depth=8, n_estimators=276, reg_alpha=0.717031151159837, reg_lambda=0.42417807246068207, subsample=0.8251420508738814; total time=   2.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.8670140089927842, gamma=9, learning_rate=0.017444866126918635, max_depth=4, n_estimators=250, reg_alpha=0.37257977798325786, reg_lambda=0.4590245141508057, subsample=0.7673825800605678; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8670140089927842, gamma=9, learning_rate=0.017444866126918635, max_depth=4, n_estimators=250, reg_alpha=0.37257977798325786, reg_lambda=0.4590245141508057, subsample=0.7673825800605678; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8670140089927842, gamma=9, learning_rate=0.017444866126918635, max_depth=4, n_estimators=250, reg_alpha=0.37257977798325786, reg_lambda=0.4590245141508057, subsample=0.7673825800605678; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8670140089927842, gamma=9, learning_rate=0.017444866126918635, max_depth=4, n_estimators=250, reg_alpha=0.37257977798325786, reg_lambda=0.4590245141508057, subsample=0.7673825800605678; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8670140089927842, gamma=9, learning_rate=0.017444866126918635, max_depth=4, n_estimators=250, reg_alpha=0.37257977798325786, reg_lambda=0.4590245141508057, subsample=0.7673825800605678; total time=   0.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.8085396792511581, gamma=8, learning_rate=0.03390942329293072, max_depth=9, n_estimators=198, reg_alpha=0.5946200350868385, reg_lambda=0.6487775097037258, subsample=0.7110412929753487; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8085396792511581, gamma=8, learning_rate=0.03390942329293072, max_depth=9, n_estimators=198, reg_alpha=0.5946200350868385, reg_lambda=0.6487775097037258, subsample=0.7110412929753487; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8085396792511581, gamma=8, learning_rate=0.03390942329293072, max_depth=9, n_estimators=198, reg_alpha=0.5946200350868385, reg_lambda=0.6487775097037258, subsample=0.7110412929753487; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8085396792511581, gamma=8, learning_rate=0.03390942329293072, max_depth=9, n_estimators=198, reg_alpha=0.5946200350868385, reg_lambda=0.6487775097037258, subsample=0.7110412929753487; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8085396792511581, gamma=8, learning_rate=0.03390942329293072, max_depth=9, n_estimators=198, reg_alpha=0.5946200350868385, reg_lambda=0.6487775097037258, subsample=0.7110412929753487; total time=   2.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.7717015338451563, gamma=9, learning_rate=0.05411797281355388, max_depth=9, n_estimators=131, reg_alpha=0.05113455367705179, reg_lambda=0.5707778026788982, subsample=0.5129005425267605; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7717015338451563, gamma=9, learning_rate=0.05411797281355388, max_depth=9, n_estimators=131, reg_alpha=0.05113455367705179, reg_lambda=0.5707778026788982, subsample=0.5129005425267605; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7717015338451563, gamma=9, learning_rate=0.05411797281355388, max_depth=9, n_estimators=131, reg_alpha=0.05113455367705179, reg_lambda=0.5707778026788982, subsample=0.5129005425267605; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7717015338451563, gamma=9, learning_rate=0.05411797281355388, max_depth=9, n_estimators=131, reg_alpha=0.05113455367705179, reg_lambda=0.5707778026788982, subsample=0.5129005425267605; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7717015338451563, gamma=9, learning_rate=0.05411797281355388, max_depth=9, n_estimators=131, reg_alpha=0.05113455367705179, reg_lambda=0.5707778026788982, subsample=0.5129005425267605; total time=   1.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.9777389931549642, gamma=7, learning_rate=0.1938811514231446, max_depth=5, n_estimators=145, reg_alpha=0.21141428727419626, reg_lambda=6.105075267348604e-05, subsample=0.6853427438313522; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9777389931549642, gamma=7, learning_rate=0.1938811514231446, max_depth=5, n_estimators=145, reg_alpha=0.21141428727419626, reg_lambda=6.105075267348604e-05, subsample=0.6853427438313522; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9777389931549642, gamma=7, learning_rate=0.1938811514231446, max_depth=5, n_estimators=145, reg_alpha=0.21141428727419626, reg_lambda=6.105075267348604e-05, subsample=0.6853427438313522; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9777389931549642, gamma=7, learning_rate=0.1938811514231446, max_depth=5, n_estimators=145, reg_alpha=0.21141428727419626, reg_lambda=6.105075267348604e-05, subsample=0.6853427438313522; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9777389931549642, gamma=7, learning_rate=0.1938811514231446, max_depth=5, n_estimators=145, reg_alpha=0.21141428727419626, reg_lambda=6.105075267348604e-05, subsample=0.6853427438313522; total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.5018151536273716, gamma=8, learning_rate=0.12444128798312445, max_depth=4, n_estimators=195, reg_alpha=0.27471484883541747, reg_lambda=0.31283930623462813, subsample=0.5762972934192222; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5018151536273716, gamma=8, learning_rate=0.12444128798312445, max_depth=4, n_estimators=195, reg_alpha=0.27471484883541747, reg_lambda=0.31283930623462813, subsample=0.5762972934192222; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5018151536273716, gamma=8, learning_rate=0.12444128798312445, max_depth=4, n_estimators=195, reg_alpha=0.27471484883541747, reg_lambda=0.31283930623462813, subsample=0.5762972934192222; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5018151536273716, gamma=8, learning_rate=0.12444128798312445, max_depth=4, n_estimators=195, reg_alpha=0.27471484883541747, reg_lambda=0.31283930623462813, subsample=0.5762972934192222; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5018151536273716, gamma=8, learning_rate=0.12444128798312445, max_depth=4, n_estimators=195, reg_alpha=0.27471484883541747, reg_lambda=0.31283930623462813, subsample=0.5762972934192222; total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.555339048236478, gamma=0, learning_rate=0.29639755098971265, max_depth=2, n_estimators=160, reg_alpha=1.0, reg_lambda=1.0, subsample=0.5; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.555339048236478, gamma=0, learning_rate=0.29639755098971265, max_depth=2, n_estimators=160, reg_alpha=1.0, reg_lambda=1.0, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.555339048236478, gamma=0, learning_rate=0.29639755098971265, max_depth=2, n_estimators=160, reg_alpha=1.0, reg_lambda=1.0, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.555339048236478, gamma=0, learning_rate=0.29639755098971265, max_depth=2, n_estimators=160, reg_alpha=1.0, reg_lambda=1.0, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.555339048236478, gamma=0, learning_rate=0.29639755098971265, max_depth=2, n_estimators=160, reg_alpha=1.0, reg_lambda=1.0, subsample=0.5; total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.5, gamma=9, learning_rate=0.21029814024813928, max_depth=2, n_estimators=195, reg_alpha=0.18633682449187308, reg_lambda=0.1443444218566546, subsample=0.5053721744895844; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, gamma=9, learning_rate=0.21029814024813928, max_depth=2, n_estimators=195, reg_alpha=0.18633682449187308, reg_lambda=0.1443444218566546, subsample=0.5053721744895844; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, gamma=9, learning_rate=0.21029814024813928, max_depth=2, n_estimators=195, reg_alpha=0.18633682449187308, reg_lambda=0.1443444218566546, subsample=0.5053721744895844; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5, gamma=9, learning_rate=0.21029814024813928, max_depth=2, n_estimators=195, reg_alpha=0.18633682449187308, reg_lambda=0.1443444218566546, subsample=0.5053721744895844; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=9, learning_rate=0.21029814024813928, max_depth=2, n_estimators=195, reg_alpha=0.18633682449187308, reg_lambda=0.1443444218566546, subsample=0.5053721744895844; total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.772882567519847, gamma=10, learning_rate=0.13352992351080145, max_depth=6, n_estimators=142, reg_alpha=0.0, reg_lambda=0.061435493773762534, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.772882567519847, gamma=10, learning_rate=0.13352992351080145, max_depth=6, n_estimators=142, reg_alpha=0.0, reg_lambda=0.061435493773762534, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.772882567519847, gamma=10, learning_rate=0.13352992351080145, max_depth=6, n_estimators=142, reg_alpha=0.0, reg_lambda=0.061435493773762534, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.772882567519847, gamma=10, learning_rate=0.13352992351080145, max_depth=6, n_estimators=142, reg_alpha=0.0, reg_lambda=0.061435493773762534, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.772882567519847, gamma=10, learning_rate=0.13352992351080145, max_depth=6, n_estimators=142, reg_alpha=0.0, reg_lambda=0.061435493773762534, subsample=0.5; total time=   0.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.5, gamma=10, learning_rate=0.29999999999999993, max_depth=2, n_estimators=300, reg_alpha=0.0, reg_lambda=0.0, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, gamma=10, learning_rate=0.29999999999999993, max_depth=2, n_estimators=300, reg_alpha=0.0, reg_lambda=0.0, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5, gamma=10, learning_rate=0.29999999999999993, max_depth=2, n_estimators=300, reg_alpha=0.0, reg_lambda=0.0, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=10, learning_rate=0.29999999999999993, max_depth=2, n_estimators=300, reg_alpha=0.0, reg_lambda=0.0, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, gamma=10, learning_rate=0.29999999999999993, max_depth=2, n_estimators=300, reg_alpha=0.0, reg_lambda=0.0, subsample=0.5; total time=   0.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=142, reg_alpha=1.0, reg_lambda=1.0, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=142, reg_alpha=1.0, reg_lambda=1.0, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=142, reg_alpha=1.0, reg_lambda=1.0, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=142, reg_alpha=1.0, reg_lambda=1.0, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=142, reg_alpha=1.0, reg_lambda=1.0, subsample=1.0; total time=   1.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.9948007133517808, gamma=7, learning_rate=0.19432149479201108, max_depth=5, n_estimators=147, reg_alpha=0.18529563471310326, reg_lambda=0.02159747738612308, subsample=0.6943218937422106; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9948007133517808, gamma=7, learning_rate=0.19432149479201108, max_depth=5, n_estimators=147, reg_alpha=0.18529563471310326, reg_lambda=0.02159747738612308, subsample=0.6943218937422106; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9948007133517808, gamma=7, learning_rate=0.19432149479201108, max_depth=5, n_estimators=147, reg_alpha=0.18529563471310326, reg_lambda=0.02159747738612308, subsample=0.6943218937422106; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9948007133517808, gamma=7, learning_rate=0.19432149479201108, max_depth=5, n_estimators=147, reg_alpha=0.18529563471310326, reg_lambda=0.02159747738612308, subsample=0.6943218937422106; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9948007133517808, gamma=7, learning_rate=0.19432149479201108, max_depth=5, n_estimators=147, reg_alpha=0.18529563471310326, reg_lambda=0.02159747738612308, subsample=0.6943218937422106; total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=1.0, gamma=6, learning_rate=0.1326027482853144, max_depth=2, n_estimators=174, reg_alpha=0.0, reg_lambda=0.7844286943345935, subsample=0.6830055268777426; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=6, learning_rate=0.1326027482853144, max_depth=2, n_estimators=174, reg_alpha=0.0, reg_lambda=0.7844286943345935, subsample=0.6830055268777426; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=6, learning_rate=0.1326027482853144, max_depth=2, n_estimators=174, reg_alpha=0.0, reg_lambda=0.7844286943345935, subsample=0.6830055268777426; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=6, learning_rate=0.1326027482853144, max_depth=2, n_estimators=174, reg_alpha=0.0, reg_lambda=0.7844286943345935, subsample=0.6830055268777426; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=6, learning_rate=0.1326027482853144, max_depth=2, n_estimators=174, reg_alpha=0.0, reg_lambda=0.7844286943345935, subsample=0.6830055268777426; total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.5654862868546546, gamma=10, learning_rate=0.13730549673005188, max_depth=2, n_estimators=231, reg_alpha=1.0, reg_lambda=0.14600115916865083, subsample=0.7700415650053284; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5654862868546546, gamma=10, learning_rate=0.13730549673005188, max_depth=2, n_estimators=231, reg_alpha=1.0, reg_lambda=0.14600115916865083, subsample=0.7700415650053284; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5654862868546546, gamma=10, learning_rate=0.13730549673005188, max_depth=2, n_estimators=231, reg_alpha=1.0, reg_lambda=0.14600115916865083, subsample=0.7700415650053284; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5654862868546546, gamma=10, learning_rate=0.13730549673005188, max_depth=2, n_estimators=231, reg_alpha=1.0, reg_lambda=0.14600115916865083, subsample=0.7700415650053284; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5654862868546546, gamma=10, learning_rate=0.13730549673005188, max_depth=2, n_estimators=231, reg_alpha=1.0, reg_lambda=0.14600115916865083, subsample=0.7700415650053284; total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.6675100650224975, gamma=10, learning_rate=0.015739822738469918, max_depth=2, n_estimators=300, reg_alpha=0.9885128054597788, reg_lambda=0.97658271022106, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6675100650224975, gamma=10, learning_rate=0.015739822738469918, max_depth=2, n_estimators=300, reg_alpha=0.9885128054597788, reg_lambda=0.97658271022106, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6675100650224975, gamma=10, learning_rate=0.015739822738469918, max_depth=2, n_estimators=300, reg_alpha=0.9885128054597788, reg_lambda=0.97658271022106, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6675100650224975, gamma=10, learning_rate=0.015739822738469918, max_depth=2, n_estimators=300, reg_alpha=0.9885128054597788, reg_lambda=0.97658271022106, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6675100650224975, gamma=10, learning_rate=0.015739822738469918, max_depth=2, n_estimators=300, reg_alpha=0.9885128054597788, reg_lambda=0.97658271022106, subsample=0.5; total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bytree=0.5914443168494512, gamma=10, learning_rate=0.26519909151070814, max_depth=10, n_estimators=129, reg_alpha=1.0, reg_lambda=0.0, subsample=0.7670261266351691; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5914443168494512, gamma=10, learning_rate=0.26519909151070814, max_depth=10, n_estimators=129, reg_alpha=1.0, reg_lambda=0.0, subsample=0.7670261266351691; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5914443168494512, gamma=10, learning_rate=0.26519909151070814, max_depth=10, n_estimators=129, reg_alpha=1.0, reg_lambda=0.0, subsample=0.7670261266351691; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5914443168494512, gamma=10, learning_rate=0.26519909151070814, max_depth=10, n_estimators=129, reg_alpha=1.0, reg_lambda=0.0, subsample=0.7670261266351691; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5914443168494512, gamma=10, learning_rate=0.26519909151070814, max_depth=10, n_estimators=129, reg_alpha=1.0, reg_lambda=0.0, subsample=0.7670261266351691; total time=   2.3s\n",
      "Best Parameters: OrderedDict([('colsample_bytree', 0.9777389931549642), ('gamma', 7), ('learning_rate', 0.1938811514231446), ('max_depth', 5), ('n_estimators', 145), ('reg_alpha', 0.21141428727419626), ('reg_lambda', 6.105075267348604e-05), ('subsample', 0.6853427438313522)])\n",
      "Best MAE: 68606.3597494177\n"
     ]
    }
   ],
   "source": [
    "def mae_scorer(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "scorer = make_scorer(\n",
    "    mae_scorer, \n",
    "    greater_is_better=False\n",
    ")\n",
    "\n",
    "# Defino o espaço de busca para cada Hiperparâmetro\n",
    "search_space = {\n",
    "    \"n_estimators\": (50, 300),\n",
    "    \"max_depth\": (2, 10),\n",
    "    \"learning_rate\": (0.01, 0.3, \"log-uniform\"),\n",
    "    \"subsample\": (0.5, 1.0, \"uniform\"),\n",
    "    \"colsample_bytree\": (0.5, 1.0, \"uniform\"),\n",
    "    \"gamma\": (0, 10), \n",
    "    \"reg_alpha\": (0, 1.0), \n",
    "    \"reg_lambda\": (0, 1.0), \n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    estimator=xgb,\n",
    "    search_spaces=search_space,\n",
    "    cv=tscv,\n",
    "    scoring=scorer, \n",
    "    n_iter=20,   \n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "opt.fit(X, y)\n",
    "\n",
    "print(\"Best Parameters:\", opt.best_params_)\n",
    "print(\"Best MAE:\", -opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/best_xgboost_model.joblib']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = opt.best_params_\n",
    "\n",
    "final_model = XGBRegressor(**best_params)\n",
    "\n",
    "final_model.fit(X, y)\n",
    "\n",
    "joblib.dump(final_model, \"../models/best_xgboost_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
